---
category: Article
article: Article 7  Amendments to Annex III.md
---

1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding [high-risk AI systems](high-risk AI systems.html) where both of the following conditions are fulfilled:
	1. {a}(a)the AI systems are intended to be used in any of the areas listed in points 1 to 8 of Annex III;
	2. (b)the AI systems pose a risk of harm to the health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the [high-risk AI systems](high-risk AI systems.html) already referred to in Annex III.

2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the [high-risk AI systems](high-risk AI systems.html)Â already referred to in Annex III, the Commission shall take into account the following criteria:
	1. {a}(a)the [intended purpose](intended purpose.html) of the AI system;
	2. (b)the extent to which an AI system has been used or is likely to be used;
	3. (c)the extent to which the use of an AI system has already caused harm to the health and safety or adverse impact on the fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities;
	4. (d)the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect a plurality of persons;
	5. (e)the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;
	6. (f)the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the [user](user.html) of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, or age;
	7. (g)the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;
	8. (h)the extent to which existing Union legislation provides for:
	9. (i)effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;
	10. (ii)effective measures to prevent or substantially minimise those risks.