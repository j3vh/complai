---
category: Article
article: Article 29  Obligations of users of high-risk AI systems.md
---

1. Users of [high-risk AI systems](high-risk AI systems.html) shall use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5.

2. The obligations in paragraph 1 are without prejudice to other [user](user.html) obligations under Union or national law and to the [[user]([[user.html)|[us](us.html)er]([user]([[user.html)|[us](us.html)er.html)’s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the [provider](provider.html).

3. Without prejudice to paragraph 1, to the extent the [user](user.html) exercises control over the [input data](input data.html), that [user](user.html) shall ensure that [input data](input data.html) is relevant in view of the [intended purpose](intended purpose.html) of the high-risk AI system.

4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 651.  they shall inform the [provider](provider.html) or [distributor](distributor.html) and suspend the use of the system. They shall also inform the [provider](provider.html) or [distributor](distributor.html) when they have identified any [serious incident](serious incident.html) or any malfunctioning within the meaning of Article 62 and interrupt the use of the AI system. In case the [user](user.html) is not able to reach the [provider](provider.html), Article 62 shall apply mutatis mutandis.

	For users that are credit institutions regulated by Directive 2013/36/EU, the monitoring obligation set out in the first subparagraph shall be deemed to be fulfilled by complying with the rules on internal governance arrangements, processes and mechanisms pursuant to Article 74 of that Directive.

5. Users of [high-risk AI systems](high-risk AI systems.html) shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of the [intended purpose](intended purpose.html) of the high-risk AI system and applicable legal obligations under Union or national law.

	Users that are credit institutions regulated by Directive 2013/36/EU shall maintain the logs as part of the documentation concerning internal governance arrangements, processes and mechanisms pursuant to Article 74 of that Directive.

6. Users of [high-risk AI systems](high-risk AI systems.html) shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, where applicable.