---
category: Article
article: Article 15  Accuracy, robustness and cybersecurity.md
---

1. [High-risk AI systems](High-risk AI systems.html) shall be designed and developed in such a way that they achieve, in the light of their [intended purpose](intended purpose.html), an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.

2. The levels of accuracy and the relevant accuracy metrics of [high-risk AI systems](high-risk AI systems.html) shall be declared in the accompanying instructions of use.

3. [High-risk AI systems](High-risk AI systems.html) shall be resilient as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.

	The robustness of [high-risk AI systems](high-risk AI systems.html) may be achieved through technical redundancy solutions, which may include backup or fail-safe plans.

	[High-risk AI systems](High-risk AI systems.html) that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs due to outputs used as an input for future operations (‘feedback loops’) are duly addressed with appropriate mitigation measures.

4. [High-risk AI systems](High-risk AI systems.html) shall be resilient as regards attempts by unauthorised third parties to alter their use or performance by exploiting the system vulnerabilities.

	The technical solutions aimed at ensuring the cybersecurity of [high-risk AI systems](high-risk AI systems.html) shall be appropriate to the relevant circumstances and the risks.

	The technical solutions to address AI specific vulnerabilities shall include, where appropriate, measures to prevent and control for attacks trying to manipulate the training dataset (‘data poisoning’), inputs designed to cause the model to make a mistake (‘adversarial examples’), or model flaws.